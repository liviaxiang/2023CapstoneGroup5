---
title: "Customer Success Analysis for Swire Coca-Cola"
author: "Vicky Mao, Katelyn Candee, Li Xiang"
output:
  html_document: default
  pdf_document: default
editor_options: 
  markdown: 
    wrap: sentence
---

## 1. Business Problem Statement

Swire Coca-Cola is seeking a solution to predicting the profitability of new partnerships with local businesses.

#### Benefits of Solution

By identifying and partnering with local businesses that align with Swire Coca-Cola and its target audience, they can increase sales and revenue for their product.<br> This will enable them to make more informed decisions, increase their reach in specific local markets, and provide a benefit for the local business.<br> Additionally, we will use data visualization tools to present the insights in an understandable format to the stakeholders.
This will help them make data-driven decisions that align with the company's strategy.<br>

#### Success Metrics

Success metrics for the model of predicting new partnerships with local businesses for Swirl Coca-Cola products may include:<br> 1.
Revenue increase: The increase in revenue generated by the new partnerships compared to previous years or to a control group.<br> 2.
ROI: The return on investment of the data science project, measured by the increase in revenue generated by the new partnerships compared to the project's cost.<br> 3.
Accuracy of predictions: The accuracy of the model's predictions in identifying potential partners and predicting the likelihood of successful partnerships.<br>

#### Approach

By utilizing predictive models such as linear regression, logistic regression, and other possible models to analyze historical data and market trends to identify local businesses that align with the brand and target audience and predict the likelihood of successful partnerships.

#### Scope and deliverables

The deliverables for this project will be a visual presentation and a written report summarizing our exploratory data analysis, model selection, evaluation and deployment process, and recommendations for applying our results.
<br> The presentation slides, written report, and all project code files will be provided to Swire Coca-Cola in the form of a GitHub repository accompanied by documentation explaining the repository contents, access, and organization.

#### Details

This project will be completed by student team members Katelyn Candee, Li Xiang and Vicky Mao by April 13, with progress checkpoints overseen by University of Utah faculty advisor Jeremy Morris on or before the following dates:<br> 1.
Exploratory data analysis - February 19 <br> 2.
Model selection, evaluation and deployment - March 19<br> 3.
Practice project presentation - April 9<br>

Project team members may be reach at:<br> 1.
Katelyn Candee - (203) 823-3129 - [u1398566\@utah.com](mailto:u1398566@utah.com){.email} <br> 2.
Li Xiang - (385) 335-4332 - [u1328517\@utah.edu](mailto:u1328517@utah.edu){.email}<br> 3.
Vicky Mao - (801) 970-0482 - [u1132288\@utah.edu](mailto:u1132288@utah.edu){.email}<br>


## 2. Data Analysis

```{r}
# Read in the data
#object_data<-read.csv("FSOP Combine Data.csv")
object_data<-read.csv("FSOP Combine Data Utah.csv")
```

### 2.1 Implement the data
```{r echo = FALSE}
Sys.setenv(LANGUAGE = "en")
```


```{r}
# Load the population data by zip code
pop_data <- read.csv("population_by_zip_2010.csv")
pop_data = pop_data[, c(1,5)]
pop_data <- pop_data[!duplicated(pop_data$zipcode), ]

```

```{r include = FALSE}
library(dplyr)
library(stringr)    
```

```{r}
# Rename the "zipcode" column in table to "ZIP_CODE"

pop_data <- pop_data %>%
  filter(str_starts(zipcode, "84"))
colnames(pop_data)[colnames(pop_data) == "zipcode"] <- "ZIP_CODE"
```

```{r}
# Merge the population data with your original table using the zip code as the key
merged_data <- merge(object_data, pop_data, by = "ZIP_CODE", all = TRUE)

```



### 2.2 Clean the data

There is a customer table and sales table provided by the Swire Coca Cola, I joined the two tables by using customer id.
The joined table is too large for my computer or R-Studio cloud to run the models.
Therefore I filtered the data, which now only contains data for Utah state.

Change some discrete attributes into factor type.

```{r}
#clean the data, mutate the factor attributes 
merged_data[c(14,15,19)]<-lapply(merged_data[c(14,15,19)],as.Date, format = "%Y-%m-%d")

merged_data <- merged_data %>%
  mutate_if(is.character, as.factor)
#merged_data[-c(8,9,10,11,12,13,14,15,16,19,22,23,31)]<-lapply(merged_data[-c(8,9,10,11,12,13,16,22,23,31)],factor)
```


```{r}
# Unload the rlang package
sum(is.na(merged_data))

```

```{r, echo = FALSE}
# Impute missing values with column mean
#merged_data <- merged_data %>%
 # mutate_if(is.numeric, ~ifelse(is.na(.), mean(., na.rm = TRUE), .))

# Impute missing values with column mode
#merged_data <- merged_data %>%
 # mutate_if(is.factor, ~ifelse(is.na(.), mode(., na.rm = TRUE), .))

```

```{r}
# Check for missing values
library(dplyr) 
merged_data <- na.omit(merged_data)
# Check for missing values
sum(is.na(merged_data))

```

```{r}
#Filter  customers with onboard date from 2010 and after
#customers_filtered <- merged_data %>%
#                      filter(ON_BOARDING_DATE >= "2011-01-01")

```

```{r}
# Create a new column 'LONGEVITY' in MERGE_DATA
#merged_data$LONGEVITY <- as.numeric(difftime(merged_data$MAX_POSTING_DATE, merged_data$ON_BOARDING_DATE, units = "days"))
library(lubridate)
merged_data$LONGEVITY <- time_length(
  difftime(merged_data$MAX_POSTING_DATE, 
           merged_data$ON_BOARDING_DATE),
  "years")

# Inspect customer longevity calculation
summary(merged_data$LONGEVITY)

```


### 2.3 Explore and Plot the relationships

-Explore the correlation of the attributes

```{r include = FALSE}
# Checking for multicollinearity and plotting correlations between predictors
#install.packages("ggcorrplot")
library(psycho) 
library(tidyverse)
library(ggplot2)
library(caret)
library(gmodels)
library(rpart)
library(e1071)
library(caret)
library(randomForest)
#install.packages("glmnet")
library(glmnet)

```

```{r}
correl <- cor(merged_data[c(8,9,10,11,12,13,31)])
ggcorrplot::ggcorrplot(correl,hc.order=TRUE, type="lower",lab=TRUE) 
cor(correl)
```

The graph above shows that some attributes are highly correlated, like INVOICE_PRICE and DEAD_NET, COGS and DEAD_NET, COGS and INVOICE_PRICE.

-Explore the correlation between LONGEVITY and GROSS_PROFIT_DEAD_NET

```{r}
# ON_BOARD_YEAR_COUNT - GROSS_PROFIT_DEAD_NET
model_lm_GROSS_PROFIT <- lm(GROSS_PROFIT_DEAD_NET ~ LONGEVITY, data = merged_data)
summary(model_lm_GROSS_PROFIT)

ggplot(merged_data,aes(x = GROSS_PROFIT_DEAD_NET, y = LONGEVITY)) + geom_point() +geom_smooth(method = "lm")

```

According to the results from the model and the plot, we get the result that the LONGEVITY is significant in predicting the gross profit  with P-Value smaller than 0.05. 
As shown in the plot, the relationship between LONGEVITY and GROSS_PROFIT_DEAD_NET is not obvious and even though they have a positive relationship, the unit increase is extremely small(3.161e-04).My assumption is that even though some local businesses are considered as long-term customer, Swire has not been making profit from them, instead Swire is getting more brand influence or simple to seize the market 


## 3. Split Data for training and testing

```{r}
#Remove the columns we do not need for the analysis.
customers_filtered <- merged_data [, -c(1,2,3,7,15,17,18,19,24,25)]
```

```{r}
#Split Data for training and testing
set.seed(123)
dt1 <-sample(nrow(customers_filtered), nrow(customers_filtered)*.7)
trainData<-customers_filtered[dt1,]
testData<-customers_filtered[-dt1,]

```


## 4. Predict the customer LONGEVITY

### 4.1 Multiple Linear Regression Model

```{r}
#The distribution of longevity using a histogram
#hist(merged_data$LONGEVITY)

# Plot a histogram of the longevity of individuals in the merged_data dataset
# using the LONGEVITY variable

longevity <- merged_data$LONGEVITY
hist(x = longevity, main = "Histogram of Longevity in Years",
     xlab = "Longevity", col = "lightblue")

# Calculate the mean of longevity
mean_longevity <- mean(longevity)

# Calculate the median of longevity
median_longevity <- median(longevity)

# Print the results
cat("Average longevity:", mean_longevity, "\n")
cat("Median longevity:", median_longevity)

```


```{r}
linear_model <- lm(LONGEVITY ~ ., data = trainData)
```



```{r}
#install.packages("Metrics")
library(Metrics)
linear_predictions <- predict(linear_model, newdata = testData[,-c(22)])
# Calculate Correlation
cor(linear_predictions, testData$LONGEVITY)
# Calculate MAE
mae(linear_predictions, testData$LONGEVITY)
# Calculate RMSE
rmse(linear_predictions, testData$LONGEVITY)
```

### 4.2 Rpart Tree Model
```{r}
#install.packages("rpart")
library(rpart)
rpart_model <- rpart(LONGEVITY ~ ., data = trainData)
rpart_model
```
```{r}
#install.packages("rpart.plot")
library(rpart.plot)
rpart.plot(rpart_model, digit = 3)

```
```{r}
rpart_predictions <- predict(rpart_model, testData)
summary((rpart_predictions))
summary(testData$LONGEVITY)
# Calculate Correlation
cor(rpart_predictions, testData$LONGEVITY)
# Calculate MAE
mae(rpart_predictions, testData$LONGEVITY)
# Calculate RMSE
rmse(rpart_predictions, testData$LONGEVITY)

```
A correlation of 0.46 is acceptable. However, the correlation only measures
how strongly the predictions are related to the true value; it is not a measure of how
far off the predictions were from the true values.

### 4.3 Gradient Boosting Model
```{r}
library(gbm)
gbm_model <- gbm(LONGEVITY ~ ., data = trainData[, -c(10)], n.trees = 500, shrinkage = 0.1)

```

```{r}
# Make predictions on the test data
glm_predictions <- predict(gbm_model, newdata = testData[, -c(10, 22)], n.trees = 500)

# Calculate R-squared
cor(glm_predictions, testData$LONGEVITY)^2
# Calculate MAE
mae(glm_predictions, testData$LONGEVITY)
# Calculate RMSE
rmse(glm_predictions, testData$LONGEVITY)

```




**Comparison of the models **
```{r echo=FALSE}
print('Multiple Linear Regression Model Result:')
postResample(linear_predictions, testData$LONGEVITY)
print('Rpart Tree Model Result:')
postResample(rpart_predictions, testData$LONGEVITY)
print('Gradient Boosting Model Result:')
postResample(glm_predictions, testData$LONGEVITY)

```


## 5. Predict the gross profit of the customer

```{r}
predictors <-trainData[, -c(6, 7, 8)]

pred_res = trainData$GROSS_PROFIT_DEAD_NET

test_predictors <-testData[, -c(6,7,8)]

```

If the customer can contribute a hight gross profit, even though the customer has the potential churned risk, company can use the prediction of gross profit to help make decisions whether or not invest on the new customer.
The predictor is GROSS_PROFIT_DEAD_NET, I am using the models as below to explore.
Multiple Linear Regression Ridge Regression Lasso Regression Elastic Net Regression Gradient Boosting Regression Neural Network Regression


### 5.1 Penalized Regression - Lasso

```{r}
#Selecting relevant predictors using penalized regression
#LASSO

#define matrix of predictor variables
predictors_matrix <-data.matrix(predictors)


#perform k-fold cross-validation to find optimal lambda value
cv_model <- cv.glmnet(predictors_matrix, pred_res, alpha = 1, standardize = TRUE, nfolds = 5)

#find optimal lambda value that minimizes test MSE
best_lambda <- cv_model$lambda.min
best_lambda


#produce plot of test MSE by lambda value
plot(cv_model) 


#find coefficients of best model
best_lasso1 <- glmnet(predictors_matrix, pred_res, alpha = 1, lambda = best_lambda, standardize = TRUE)
coef(best_lasso1)


```

```{r}
test_predictors <- data.matrix(test_predictors)
test_response <- testData$GROSS_PROFIT_DEAD_NET
lasso_predictions <- predict(best_lasso1, newx = test_predictors)


postResample(lasso_predictions, testData$GROSS_PROFIT_DEAD_NET)

mse <- mean((test_response - lasso_predictions)^2)
print(paste("Test set mean squared error:", mse))
```


### 5.2 Penalized Regression - Ridge
```{r}
#Ridge
#perform k-fold cross-validation to find optimal lambda value
cv_ridge <- cv.glmnet(predictors_matrix, pred_res, alpha = 0,family = 'gaussian', standardize = TRUE, nfolds = 5)

optimal_lambda <- cv_ridge$lambda.min
optimal_lambda

#produce plot of test MSE by lambda value
plot(optimal_lambda) 

#find coefficients of best model
best_ridge1 <- glmnet(predictors_matrix, pred_res, alpha = 0, lambda = optimal_lambda, standardize = TRUE)
coef(best_ridge1)

```


```{r}
ridge_predictions <- predict(best_ridge1, newx = test_predictors)


postResample(ridge_predictions, testData$GROSS_PROFIT_DEAD_NET)

mse <- mean((test_response - ridge_predictions)^2)
print(paste("Test set mean squared error:", mse))
```

### 5.3 Elastic net regression

```{r}
# Fit the Elastic net model
#install.packages("glmnet")
library(glmnet)

fit <- glmnet(x = predictors_matrix, y = pred_res, alpha = 0.5, lambda = seq(0.1, 1, by = 0.1))


# Predict the outcome variable on the test set
elas_prediction <- predict(fit, newx = test_predictors, s = 0.5)

# Calculate the mean squared error
postResample(elas_prediction, testData$GROSS_PROFIT_DEAD_NET)
mse <- mean((test_response - ridge_predictions)^2)
print(paste("Test set mean squared error:", mse))

```

Elastic net regression is a regularized linear regression method that combines L1 and L2 regularization.
It is used to prevent overfitting and improve the accuracy of the model when there are many features.

The L1 regularization term encourages sparsity in the coefficient estimates, which means that some of the coefficients are set to zero, effectively removing those features from the model.
The L2 regularization term, on the other hand, penalizes large coefficients, which helps to prevent overfitting.

The Elastic net method combines these two regularization methods and allows for a flexible trade-off between sparsity and smoothness in the coefficient estimates.

### 5.4 Gradient Boosting Regression

```{r}

# Load the gbm package
#install.packages("gbm")
library(gbm)

# Fit a gradient boosting regression model with 100 trees and 0.01 shrinkage

gb_model <- gbm(GROSS_PROFIT_DEAD_NET ~ ., data = trainData[,-c(10)], distribution = "gaussian", n.trees = 500, interaction.depth = 3, shrinkage = 0.01)

```

```{r}
# Make predictions on the test set
gb_pred <- predict(gb_model, newdata = testData, n.trees = 1000)

# Evaluate the performance of the model on the test set
postResample(gb_pred, testData$GROSS_PROFIT_DEAD_NET)
rf_mse <- mean((testData$GROSS_PROFIT_DEAD_NET - gb_pred)^2)
print(paste("Random Forest Regression MSE:", rf_mse))

```



**Comparison of the models **

```{r echo=FALSE}
print('Lasso Model Result:')
postResample(lasso_predictions, testData$GROSS_PROFIT_DEAD_NET)
print('Rideg Model Result:')
postResample(ridge_predictions, testData$GROSS_PROFIT_DEAD_NET)
print('Elastic Model Result:')
postResample(elas_prediction, testData$GROSS_PROFIT_DEAD_NET)
print('Gradient Boosting Result:')
postResample(gb_pred, testData$GROSS_PROFIT_DEAD_NET)
```

Perform business validation of the model.
Are your results sufficient to solve the business problem?
Based on the results, I would choos Gardient Boosting Model, since it has lower MSRE, higher R-Squared.
