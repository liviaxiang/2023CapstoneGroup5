---
title: "Customer Success Analysis for Swire Coca-Cola"
author: "Li Xiang"
output:
  html_document: default
  pdf_document: default
editor_options: 
  markdown: 
    wrap: sentence
---

## 1. Business Problem Statement

Swire Coca-Cola is seeking a solution to predicting the profitability of new partnerships with local businesses.

#### Benefits of Solution

By identifying and partnering with local businesses that align with Swire Coca-Cola and its target audience, they can increase sales and revenue for their product.<br> This will enable them to make more informed decisions, increase their reach in specific local markets, and provide a benefit for the local business.<br> Additionally, we will use data visualization tools to present the insights in an understandable format to the stakeholders.
This will help them make data-driven decisions that align with the company's strategy.<br>

#### Success Metrics

Success metrics for the model of predicting new partnerships with local businesses for Swirl Coca-Cola products may include:<br> 1.
Revenue increase: The increase in revenue generated by the new partnerships compared to previous years or to a control group.<br> 2.
ROI: The return on investment of the data science project, measured by the increase in revenue generated by the new partnerships compared to the project's cost.<br> 3.
Accuracy of predictions: The accuracy of the model's predictions in identifying potential partners and predicting the likelihood of successful partnerships.<br>

#### Approach

By utilizing predictive models such as linear regression, logistic regression, and other possible models to analyze historical data and market trends to identify local businesses that align with the brand and target audience and predict the likelihood of successful partnerships.

#### Scope and deliverables

The deliverables for this project will be a visual presentation and a written report summarizing our exploratory data analysis, model selection, evaluation and deployment process, and recommendations for applying our results.
<br> The presentation slides, written report, and all project code files will be provided to Swire Coca-Cola in the form of a GitHub repository accompanied by documentation explaining the repository contents, access, and organization.

#### Details

This project will be completed by student team members Katelyn Candee, Li Xiang and Vicky Mao by April 13, with progress checkpoints overseen by University of Utah faculty advisor Jeremy Morris on or before the following dates:<br> 1.
Exploratory data analysis - February 19 <br> 2.
Model selection, evaluation and deployment - March 19<br> 3.
Practice project presentation - April 9<br>

Project team members may be reach at:<br> 1.
Katelyn Candee - (203) 823-3129 - [u1398566\@utah.com](mailto:u1398566@utah.com){.email} <br> 2.
Li Xiang - (385) 335-4332 - [u1328517\@utah.edu](mailto:u1328517@utah.edu){.email}<br> 3.
Vicky Mao - (801) 970-0482 - [u1132288\@utah.edu](mailto:u1132288@utah.edu){.email}<br>

https://towardsdatascience.com/predict-customer-churn-with-r-9e62357d47b4

## 2. Data Analysis

```{r}
# Read in the data
#object_data<-read.csv("FSOP Combine Data.csv")
object_data<-read.csv("FSOP Combine Data Utah.csv")
```

### 2.1 Implement the data
```{r echo = FALSE}
Sys.setenv(LANGUAGE = "en")
```


```{r}
# Load the population data by zip code
pop_data <- read.csv("population_by_zip_2010.csv")
pop_data = pop_data[, c(1,5)]
pop_data <- pop_data[!duplicated(pop_data$zipcode), ]

```

```{r include = FALSE}
library(dplyr)
library(stringr)    
```

```{r}
# Rename the "zipcode" column in table to "ZIP_CODE"

pop_data <- pop_data %>%
  filter(str_starts(zipcode, "84"))
colnames(pop_data)[colnames(pop_data) == "zipcode"] <- "ZIP_CODE"
```

```{r}
# Merge the population data with your original table using the zip code as the key
merged_data <- merge(object_data, pop_data, by = "ZIP_CODE", all = TRUE)

```



### 2.2 Clean the data

There is a customer table and sales table provided by the Swire Coca Cola, I joined the two tables by using customer id.
The joined table is too large for my computer or R-Studio cloud to run the models.
Therefore I filtered the data, which now only contains data for Utah state.

Change some discrete attributes into factor type.

```{r}
#clean the data, mutate the factor attributes 
merged_data[c(14,15,19)]<-lapply(merged_data[c(14,15,19)],as.Date, format = "%Y-%m-%d")
merged_data[-c(8,9,10,11,12,13,14,15,16,19,22,23,31)]<-lapply(merged_data[-c(8,9,10,11,12,13,16,22,23,31)],factor)

```


```{r}
# Unload the rlang package
sum(is.na(merged_data))

```

```{r, echo = FALSE}
# Impute missing values with column mean
#merged_data <- merged_data %>%
 # mutate_if(is.numeric, ~ifelse(is.na(.), mean(., na.rm = TRUE), .))

# Impute missing values with column mode
#merged_data <- merged_data %>%
 # mutate_if(is.factor, ~ifelse(is.na(.), mode(., na.rm = TRUE), .))

```

```{r}
# Check for missing values
library(dplyr) 
merged_data <- na.omit(merged_data)
# Check for missing values
sum(is.na(merged_data))

```

```{r}
#Filter  customers with onboard date from 2010 and after
customers_filtered <- merged_data %>%
                      filter(ON_BOARDING_DATE >= "2011-01-01")

```

```{r}
# define the churned customer and add the column in the dataset

customers_filtered <- customers_filtered %>%
  mutate(CHURNED = ifelse(MAX_POSTING_DATE < "2022-01-01", "YES", "NO"))

customers_filtered$CHURNED <- factor(customers_filtered$CHURNED)
```


### 2.3 Explore and Plot the relationships

The gross_profit_dead_net would be the predictor variable.

-Explore the correlation of the attributes

```{r include = FALSE}
# Checking for multicollinearity and plotting correlations between predictors
#install.packages("ggcorrplot")
library(psycho) 
library(tidyverse)
library(ggplot2)
library(caret)
library(gmodels)
library(rpart)
library(e1071)
library(caret)
library(randomForest)
#install.packages("glmnet")
library(glmnet)

```

```{r}
correl <- cor(customers_filtered[c(8,9,10,11,12,13,31)])
ggcorrplot::ggcorrplot(correl,hc.order=TRUE, type="lower",lab=TRUE) 
cor(correl)
```

The graph above shows that some attributes are highly correlated, like INVOICE_PRICE and DEAD_NET, COGS and DEAD_NET, COGS and INVOICE_PRICE.

## 3. Split Data for training and testing

```{r}
#Remove the columns we do not need for the analysis.
customers_filtered <- customers_filtered [, -c(1,2,3,4, 17,18,24)]

```


```{r}
#Split Data for training and testing
set.seed(123)
dt1 <-sample(nrow(customers_filtered), nrow(customers_filtered)*.7)
trainData<-customers_filtered[dt1,]
testData<-customers_filtered[-dt1,]

```


## 4. Predict the churn customer

### 4.1 Logistic Regression Model


```{r}
# Build the logistic regression model
trainData$PACK_SIZE_SALES_UNIT_DESCRIPTION <- factor(trainData$PACK_SIZE_SALES_UNIT_DESCRIPTION, levels = c("1150 GM", "1-Ls", "12", "12 OZ", "12OZ LIDS2000 PLASTIC", "20 OZ 4-Pk", "24", "32 OZ", "1000"))
testData$PACK_SIZE_SALES_UNIT_DESCRIPTION <- factor(testData$PACK_SIZE_SALES_UNIT_DESCRIPTION, levels = c("1150 GM", "1-Ls", "12", "12 OZ", "12OZ LIDS2000 PLASTIC", "20 OZ 4-Pk", "24", "32 OZ", "1000"))

logistic_model <- glm(CHURNED ~ ., data = trainData[,-c(3,18)], family = binomial(link="logit"))
#Print(summary(logistic_model))

# Make predictions on the test data
glm_predictions <- predict(logistic_model, newdata = testData, type = "response")

# Convert probabilities to binary predictions
glm_predictions <- ifelse(glm_predictions >= 0.5, 'Yes', 'No')

# Calculate model accuracy
CrossTable(testData$CHURNED, glm_predictions)
```

```{r}
glm_accuracy = (19055 + 5654) / 25050

print(paste0("Logistic Regression Accuracy: ", glm_accuracy))

```



### 4.2 Decision Tree Model

```{r}
# Build the decision tree model
tree_model <- rpart(CHURNED ~ ., data = trainData, method = "class")

# Make predictions on the test data
tree_predictions <- predict(tree_model, newdata = testData, type = "class")

# Calculate model accuracy
CrossTable(testData$CHURNED, tree_predictions)
tree_accuracy <- mean(tree_predictions == testData$CHURNED)
confusionMatrix(tree_predictions, testData$CHURNED)

```

### 4.3 Naive Bayes Model

```{r}
naive_bayes_model <- naiveBayes(CHURNED ~ ., data = trainData)
naive_predictions <- predict(naive_bayes_model, newdata = testData)

# Calculate model accuracy
CrossTable(testData$CHURNED, naive_predictions)
naive_accuracy <- mean(naive_predictions == testData$CHURNED)
confusionMatrix(naive_predictions, testData$CHURNED)

```

### 4.4 Random Forest Model

```{r}
rfModel <- randomForest(CHURNED ~., trainData[,-c(3,18)])
rf_predictions <- predict(rfModel, testData)
# Calculate model accuracy
CrossTable(testData$CHURNED, rf_predictions)
rf_accuracy <- mean(rf_predictions == testData$CHURNED)
confusionMatrix(rf_predictions, testData$CHURNED)
```

**Comparison of the models **
```{r echo=FALSE}
print(paste0("Logistic Regression Accuracy: ", glm_accuracy))
print(paste0("Decision Tree Accuracy: ", tree_accuracy))
print(paste0("Naive Bayes Model Accuracy: ", naive_accuracy))
print(paste0("Random Forest Model Accuracy: ", rf_accuracy))
```


## 5. Predict the gross profit of the customer

```{r}
predictors <-trainData[,-c(3)]

pred_res = trainData$GROSS_PROFIT_DEAD_NET

test_predictors <-testData[,-c(3)]

```

If the customer can contribute a hight gross profit, even though the customer has the potential churned risk, company can use the prediction of gross profit to help make decisions whether or not invest on the new customer.
The predictor is GROSS_PROFIT_DEAD_NET, I am using the models as below to explore.
Multiple Linear Regression Ridge Regression Lasso Regression Elastic Net Regression Gradient Boosting Regression Neural Network Regression


### 5.1 Penalized Regression - Lasso

```{r}
#Selecting relevant predictors using penalized regression
#LASSO

#define matrix of predictor variables
predictors_matrix <-data.matrix(predictors)


#perform k-fold cross-validation to find optimal lambda value
cv_model <- cv.glmnet(predictors_matrix, pred_res, alpha = 1, standardize = TRUE, nfolds = 5)

#find optimal lambda value that minimizes test MSE
best_lambda <- cv_model$lambda.min
best_lambda


#produce plot of test MSE by lambda value
plot(cv_model) 


#find coefficients of best model
best_lasso1 <- glmnet(predictors_matrix, pred_res, alpha = 1, lambda = best_lambda, standardize = TRUE)
coef(best_lasso1)


```

```{r}
test_predictors <- data.matrix(test_predictors)
test_response <- testData$GROSS_PROFIT_DEAD_NET
lasso_predictions <- predict(best_lasso1, newx = test_predictors)


postResample(lasso_predictions, testData$GROSS_PROFIT_DEAD_NET)

mse <- mean((test_response - lasso_predictions)^2)
print(paste("Test set mean squared error:", mse))
```


### 5.2 Penalized Regression - Ridge
```{r}
#Ridge
#perform k-fold cross-validation to find optimal lambda value
cv_ridge <- cv.glmnet(predictors_matrix, pred_res, alpha = 0,family = 'gaussian', standardize = TRUE, nfolds = 5)

optimal_lambda <- cv_ridge$lambda.min
optimal_lambda

#produce plot of test MSE by lambda value
plot(optimal_lambda) 

#find coefficients of best model
best_ridge1 <- glmnet(predictors_matrix, pred_res, alpha = 0, lambda = optimal_lambda, standardize = TRUE)
coef(best_ridge1)

```


```{r}
ridge_predictions <- predict(best_ridge1, newx = test_predictors)


postResample(ridge_predictions, testData$GROSS_PROFIT_DEAD_NET)

mse <- mean((test_response - ridge_predictions)^2)
print(paste("Test set mean squared error:", mse))
```

### 5.3 Elastic net regression

```{r}
# Fit the Elastic net model
#install.packages("glmnet")
library(glmnet)

fit <- glmnet(x = predictors_matrix, y = pred_res, alpha = 0.5, lambda = seq(0.1, 1, by = 0.1))


# Predict the outcome variable on the test set
elas_prediction <- predict(fit, newx = test_predictors, s = 0.5)

# Calculate the mean squared error
postResample(elas_prediction, testData$GROSS_PROFIT_DEAD_NET)
mse <- mean((test_response - ridge_predictions)^2)
print(paste("Test set mean squared error:", mse))

```

Elastic net regression is a regularized linear regression method that combines L1 and L2 regularization.
It is used to prevent overfitting and improve the accuracy of the model when there are many features.

The L1 regularization term encourages sparsity in the coefficient estimates, which means that some of the coefficients are set to zero, effectively removing those features from the model.
The L2 regularization term, on the other hand, penalizes large coefficients, which helps to prevent overfitting.

The Elastic net method combines these two regularization methods and allows for a flexible trade-off between sparsity and smoothness in the coefficient estimates.

### 5.4 Gradient Boosting Regression

```{r}

# Load the gbm package
#install.packages("gbm")
library(gbm)

# Fit a gradient boosting regression model with 100 trees and 0.01 shrinkage

gb_model <- gbm(GROSS_PROFIT_DEAD_NET ~ ., data = trainData[,-c(3,10,11,13)], distribution = "gaussian", n.trees = 1000, interaction.depth = 3, shrinkage = 0.01)

```

```{r}
# Make predictions on the test set
gb_pred <- predict(gb_model, newdata = testData, n.trees = 1000)

# Evaluate the performance of the model on the test set
postResample(gb_pred, testData$GROSS_PROFIT_DEAD_NET)
rf_mse <- mean((testData$GROSS_PROFIT_DEAD_NET - gb_pred)^2)
print(paste("Random Forest Regression MSE:", rf_mse))

```


### 5.5 Neural Network Regression**

```{r}
# Load the nnet package
#install.packages("nnet")
library(nnet)

# Fit a neural network regression model using only the selected predictors
nn_model <- nnet(GROSS_PROFIT_DEAD_NET ~ ., data = trainData[,c(3,4,5,7,8,9,10,11,15,16,17)], size = 1, linout = TRUE)

# Predict the outcome variable on the test set using the selected predictors
pred_nn <- predict(nn_model, newdata = testData[,c(3,4,5,7,8,9,10,11,15,16,17)])

# Make predictions on the test set
nn_pred <- predict(nn_model, newdata = testData)

# Evaluate the performance of the model on the test set
postResample(nn_pred, testData$GROSS_PROFIT_DEAD_NET)
nn_mse <- mean((testData$GROSS_PROFIT_DEAD_NET - nn_pred)^2)
print(paste("Neural Network Regression MSE:", nn_mse))

```


**Comparison of the models **

```{r echo=FALSE}
print('Lasso Model Result:')
postResample(lasso_predictions, testData$GROSS_PROFIT_DEAD_NET)
print('Rideg Model Result:')
postResample(ridge_predictions, testData$GROSS_PROFIT_DEAD_NET)
print('Elastic Model Result:')
postResample(elas_prediction, testData$GROSS_PROFIT_DEAD_NET)
print('Gradient Boosting Result:')
postResample(gb_pred, testData$GROSS_PROFIT_DEAD_NET)
print('Neural Network Regression Result:')
postResample(nn_pred, testData$GROSS_PROFIT_DEAD_NET)
```

Perform business validation of the model.
Are your results sufficient to solve the business problem?
Based on the results, I would choos Lasso Regression Model, since it has lower MSRE, higher R-Squared.
